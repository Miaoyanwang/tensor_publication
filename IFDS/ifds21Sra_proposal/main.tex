

\documentclass[11pt]{article}

\usepackage{fancybox}


\usepackage{color}
\usepackage{url}
\usepackage[margin=1in]{geometry}

\setlength\parindent{0pt}
\renewcommand{\textfraction}{0.0}
\renewcommand{\topfraction}{1.0}
%\renewcommand{\textfloatsep}{5mm}

\usepackage{comment}
% Definitions of handy macros can go here
\usepackage{amsmath,amssymb,amsthm,bm,mathtools}
\usepackage{multirow}
\usepackage{extarrows}
\usepackage{dsfont,multirow,hyperref,setspace,natbib,enumerate}
%\usepackage{dsfont,multirow,hyperref,setspace,enumerate}
\hypersetup{colorlinks,linkcolor={blue},citecolor={blue},urlcolor={red}} 
\usepackage{algpseudocode,algorithm}
\algnewcommand\algorithmicinput{\textbf{Input:}}
\algnewcommand\algorithmicoutput{\textbf{Output:}}
\algnewcommand\INPUT{\item[\algorithmicinput]}
\algnewcommand\OUTPUT{\item[\algorithmicoutput]}

\mathtoolsset{showonlyrefs=true}



\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}{Lemma}
\newtheorem{prop}{Proposition}
\newtheorem{pro}{Property}
\newtheorem{assumption}{Assumption}

\theoremstyle{definition}
\newtheorem{defn}{Definition}
\newtheorem{cor}{Corollary}
\newtheorem{example}{Example}
\newtheorem{rmk}{Remark}


\setcounter{figure}{0}   
\setcounter{table}{0}  



\newcommand{\of}[1]{\left(#1\right)}
\newcommand{\off}[1]{\left[#1\right]}
\newcommand{\offf}[1]{\left\{#1\right\}}
\newcommand{\aabs}[1]{\left|#1\right|}





\newcommand{\cmt}[1]{{\leavevmode\color{red}{#1}}}

\usepackage{dsfont}
\usepackage{multirow}

\DeclareMathOperator*{\minimize}{minimize}



\usepackage{mathtools}
\mathtoolsset{showonlyrefs}
\newcommand*{\KeepStyleUnderBrace}[1]{%f
  \mathop{%
    \mathchoice
    {\underbrace{\displaystyle#1}}%
    {\underbrace{\textstyle#1}}%
    {\underbrace{\scriptstyle#1}}%
    {\underbrace{\scriptscriptstyle#1}}%
  }\limits
}
\usepackage{xr}



\input macros.tex

\setlength{\parskip}{0.8em}

\title{IFDS 2021 Spring RA research proposal}

\date{\today}
\author{%
Jiaxin Hu
}



\begin{document}

% Makes the title and author information appear.

\maketitle

My research interests lie in the statistical machine learning and matrix/tensor data analysis. I am currently a second-year Ph.D.\ student in Statistics. I am planning to work under the supervision of Prof. Miaoyan Wang (Ph.D.\ advisor) and Prof. Xiaojin (Jerry) Zhu (co-mentor).

I have been working on statistical methods for tensor analysis, and I plan to continue the research on tensor methodology in the next semester. 

\textbf{I plan to develop a semi-supervised higher-order clustering method.} Higher-order clustering problem aims to identify the similarity among entities (e.g.\ people in the social network) via multiway arrays, which is a higher-order extension of one-dimensional clustering and matrix biclustering. Amount of unsupervised tensor models and tools for higher-order clustering have arisen recently. Meanwhile, semi-supervised learning method is widely employed in vector and matrix clustering with prior information. The potential useful prior information such as a small proportion of labeled data and auxiliary features is believed to improve clustering performance than unsupervised methods. However, applying semi-supervised techniques in higher-order clustering is still new to the field. I will propose a semi-supervised higher-order clustering method, and answer the two key questions: (1) how to incorporate prior information in tensor models; (2) how the prior information affects the clustering performance. I expect the proposed method will enrich the higher-order clustering methodology and deepen the understanding of semi-supervised learning in higher-order regime.

\textbf{I also plan to actively participate the IFDS events and present my research work at IFDS next semester.} I have regularly attended IFDS seminars since 2019. I also attended IFDS summer school and presented my previous work on generalized tensor decomposition during the lighting talk session of the IFDS-MADLab workshop this August. I will keep interacting with IFDS faculty/members and contributing to the community.

% Multiway arrays are collected in many fields including social networks \citep{anandkumar2014tensor} and computer science \citep{koniusz2016sparse}, and tensors represent the multiway data efficiently. One example is \emph{hypergraph} network~\citep{ghoshdastidar2017uniform,ghoshdastidar2017consistency,ahn2019community,ke2019community} in social science. A $K$-uniform hypergraph can be naturally represented as an order-$K$ tensor, in which each entry indicates the presence of $K$-way hyperedge among nodes. Identifying the similarity among nodes is of scientific interests.  We refer such clustering as \emph{higher-order clustering}. A huge amounts methods have been developed for matrix clustering while applying matrix methods to tensors results in sub-optimal performances. Unsupervised tensor models and tools for higher-order clustering have arisen recently~\citep{ wang2019multiway,chi2020provable,han2020exact}. 

% Meanwhile, semi-supervised learning has been widely applied to clustering problems~\citep{zhu2003semi,yang2014unified}. The potential useful prior information such as a small proportion of labeled data and auxiliary features are well-incorporated in the learning tasks, which is believed to improve clustering performance than unsupervised methods. Semi-supervised learning are also used in tensor decomposition~\citep{cao2016semi,hu2021generalized}. However, applying semi-supervised techniques in higher-order clustering is still new to the field. Several questions such as how to incorporate prior information in tensor models and how the prior information affects the clustering performance are waiting to be answered. 

% Therefore, this project will focus on the application of semi-supervised learning in higher-order clustering problem. The work will enrich the methodology in higher-order clustering literature and deepen the understanding of semi-supervised learning in higher-order regime, which tackles the main theme of IFDS. 


% \textbf{Bio:} 

% Jiaxin Hu is a second-year Ph.D.\ student in Statistics at the University of Wisconsin-Madison, advised by Prof. Miaoyan Wang. Her research mainly focuses on the statistical machine learning methods for matrix/tensor data analysis. She actively attended the weekly IFDS seminars and the IFDS summer school and IFDS-MADLab workshop this August, 2021. During the workshop, she gave a five minute lightening talk with title ``Supervised tensor decomposition with features on multiple modes". 

\bibliography{tensor_wang.bib}
\bibliographystyle{apalike}


\end{document}

