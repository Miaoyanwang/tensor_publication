\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@nameuse{bbl@beforestart}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {A}Proofs}{1}{appendix.A}\protected@file@percent }
\newlabel{sec:appedix}{{A}{1}{Proofs}{appendix.A}{}}
\newlabel{thm:main}{{A.1}{1}{Statistical convergence}{thm.A.1}{}}
\MT@newlabel{eq:decomp}
\MT@newlabel{eq:MLE}
\newlabel{eq:bound}{{1}{1}{Statistical convergence}{equation.A.1}{}}
\newlabel{eq:sinebound}{{A.1}{1}{Statistical convergence}{equation.A.1}{}}
\MT@newlabel{eq:bound}
\citation{wang2017operator,wang2018learning}
\citation{tomioka2014spectral}
\MT@newlabel{eq:loglikelihood}
\newlabel{bound}{{2}{2}{Proofs}{equation.A.2}{}}
\MT@newlabel{bound}
\newlabel{eq:bound2}{{3}{2}{Proofs}{equation.A.3}{}}
\MT@newlabel{eq:bound2}
\newlabel{eq:logbefore}{{A}{2}{Proofs}{equation.A.3}{}}
\MT@newlabel{eq:log}
\newlabel{eq:log}{{4}{3}{Proofs}{equation.A.4}{}}
\MT@newlabel{eq:log}
\newlabel{eq:logB}{{A}{3}{Proofs}{equation.A.4}{}}
\MT@newlabel{eq:log}
\newlabel{upper}{{5}{3}{Proofs}{equation.A.5}{}}
\newlabel{eq:F-norm}{{6}{3}{Proofs}{equation.A.6}{}}
\MT@newlabel{upper}
\citation{rudelson2010non}
\MT@newlabel{eq:F-norm}
\newlabel{eq:1}{{7}{4}{Proofs}{equation.A.7}{}}
\MT@newlabel{eq:1}
\newlabel{eq:theta}{{8}{4}{Proofs}{equation.A.8}{}}
\newlabel{eq:Bbound}{{9}{4}{Proofs}{equation.A.9}{}}
\newlabel{eq:case1}{{10}{4}{Proofs}{equation.A.10}{}}
\newlabel{eq:case2}{{11}{4}{Proofs}{equation.A.11}{}}
\MT@newlabel{eq:Bbound}
\MT@newlabel{eq:case1}
\MT@newlabel{eq:case2}
\newlabel{eq:sintheta}{{12}{5}{Proofs}{equation.A.12}{}}
\MT@newlabel{eq:sintheta}
\MT@newlabel{eq:bound}
\newlabel{prop:sub}{{1}{5}{sub-Gaussian tensors}{prop.1}{}}
\citation{fan2019generalized}
\citation{wang2017tensor}
\newlabel{prop}{{2}{6}{sub-Gaussian residuals}{prop.2}{}}
\newlabel{prop:sinebound}{{3}{6}{Wedin's $\sin \Theta $ Theorem}{prop.3}{}}
\newlabel{eq:sine}{{13}{6}{Wedin's $\sin \Theta $ Theorem}{equation.A.13}{}}
\citation{pmlr-v108-berthet20a}
\MT@newlabel{eq:sine}
\MT@newlabel{eq:log}
\MT@newlabel{eq:theta}
\@writefile{toc}{\contentsline {section}{\numberline {B}Algorithm properties}{7}{appendix.B}\protected@file@percent }
\newlabel{sec:SAlgorithm}{{B}{7}{Algorithm properties}{appendix.B}{}}
\citation{Lange:2012:NAS:2432073}
\newlabel{eq:equivalance}{{1}{8}{Equivalance relation}{defn.1}{}}
\MT@newlabel{eq:equivalance}
\citation{kolda2009tensor}
\@writefile{toc}{\contentsline {section}{\numberline {C}Computational complexity}{9}{appendix.C}\protected@file@percent }
\MT@newlabel{alg:B}
\@writefile{toc}{\contentsline {section}{\numberline {D}Additional simulation results}{9}{appendix.D}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {S1}{\ignorespaces Comparison of MSPE versus the number of modes with features. We consider full combinations of rank $\bm  {r}=(3,3,3)$ (low), $\bm  {r}=(4,5,6)$ (high), and signal $\alpha =3$ (low), $\alpha =6$ (high).}}{10}{figure.1}\protected@file@percent }
\newlabel{fig:S1}{{S1}{10}{Comparison of MSPE versus the number of modes with features. We consider full combinations of rank $\mr =(3,3,3)$ (low), $\mr =(4,5,6)$ (high), and signal $\alpha =3$ (low), $\alpha =6$ (high)}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S2}{\ignorespaces Comparison of MSPE versus effective sample size. We consider full combinations rank $\bm  {r}=(3,3,3)$ (low), $\bm  {r}=(4,5,6)$ (high), and signal $\alpha =3$ (low), $\alpha =6$ (high). }}{11}{figure.2}\protected@file@percent }
\newlabel{fig:S2}{{S2}{11}{Comparison of MSPE versus effective sample size. We consider full combinations rank $\mr =(3,3,3)$ (low), $\mr =(4,5,6)$ (high), and signal $\alpha =3$ (low), $\alpha =6$ (high)}{figure.2}{}}
\bibdata{tensor_wang}
\bibcite{pmlr-v108-berthet20a}{{1}{2020}{{Berthet and Baldin}}{{}}}
\bibcite{fan2019generalized}{{2}{2019}{{Fan et~al.}}{{}}}
\bibcite{kolda2009tensor}{{3}{2009}{{Kolda and Bader}}{{}}}
\bibcite{Lange:2012:NAS:2432073}{{4}{2012}{{Lange}}{{}}}
\bibcite{rudelson2010non}{{5}{2010}{{Rudelson and Vershynin}}{{}}}
\bibcite{tomioka2014spectral}{{6}{2014}{{Tomioka and Suzuki}}{{}}}
\bibcite{wang2017operator}{{7}{2017}{{Wang et~al.}}{{}}}
\bibcite{wang2018learning}{{8}{2020}{{Wang and Li}}{{}}}
\bibcite{wang2017tensor}{{9}{2017}{{Wang and Song}}{{}}}
\bibstyle{apalike}
